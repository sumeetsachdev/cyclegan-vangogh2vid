# -*- coding: utf-8 -*-
"""VanGogh2Vid.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1p74m0qkF3h8zEBTrbWrpAiZlGXjKuDBx
"""



#!pip install git+https://www.github.com/keras-team/keras-contrib.git

import numpy as np
from matplotlib import pyplot as plt
from keras.optimizers import Adam
from keras.initializers import RandomNormal
from keras.models import Model
from keras.models import Input
from keras.models import load_model
from keras.layers import Conv2D
from keras.layers import Conv2DTranspose
from keras.layers import LeakyReLU, ReLU
from keras.layers import Activation
from keras.layers import Concatenate
from keras_contrib.layers.normalization.instancenormalization import InstanceNormalization

def define_discriminator(image_shape):
	init = RandomNormal(stddev=0.02)

	in_image = Input(shape=image_shape)

	d = Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(in_image)
	d = LeakyReLU(alpha=0.2)(d)
	
	d = Conv2D(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)
	d = InstanceNormalization(axis=-1)(d)
	d = LeakyReLU(alpha=0.2)(d)
	
	d = Conv2D(256, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)
	d = InstanceNormalization(axis=-1)(d)
	d = LeakyReLU(alpha=0.2)(d)
	
	d = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)
	d = InstanceNormalization(axis=-1)(d)
	d = LeakyReLU(alpha=0.2)(d)
	
	d = Conv2D(512, (4,4), padding='same', kernel_initializer=init)(d)
	d = InstanceNormalization(axis=-1)(d)
	d = LeakyReLU(alpha=0.2)(d)
	
	patch_out = Conv2D(1, (4,4), padding='same', kernel_initializer=init)(d)
	
	model = Model(in_image, patch_out)
	
	model.compile(loss='mse', optimizer=Adam(lr=0.0002, beta_1=0.5), loss_weights=[0.5])
	return model

def resnet_block(n_filters, input_layer):

	init = RandomNormal(stddev=0.02)

	g = Conv2D(n_filters, (3,3), padding='same', kernel_initializer=init)(input_layer)
	g = InstanceNormalization(axis=-1)(g)
	g = Activation('relu')(g)

	g = Conv2D(n_filters, (3,3), padding='same', kernel_initializer=init)(g)
	g = InstanceNormalization(axis=-1)(g)

	g = Concatenate()([g, input_layer])

	return g

def define_generator(image_shape, n_resnet=9):
	init = RandomNormal(stddev=0.02)
	
	in_image = Input(shape=image_shape)
	
	g = Conv2D(64, (7,7), padding='same', kernel_initializer=init)(in_image)
	g = InstanceNormalization(axis=-1)(g)
	g = Activation('relu')(g)
	
	g = Conv2D(128, (3,3), strides=(2,2), padding='same', kernel_initializer=init)(g)
	g = InstanceNormalization(axis=-1)(g)
	g = Activation('relu')(g)
	
	g = Conv2D(256, (3,3), strides=(2,2), padding='same', kernel_initializer=init)(g)
	g = InstanceNormalization(axis=-1)(g)
	g = Activation('relu')(g)
	
	for _ in range(n_resnet):
		g = resnet_block(256, g)
	
	g = Conv2DTranspose(128, (3,3), strides=(2,2), padding='same', kernel_initializer=init)(g)
	g = InstanceNormalization(axis=-1)(g)
	g = Activation('relu')(g)
	
	g = Conv2DTranspose(64, (3,3), strides=(2,2), padding='same', kernel_initializer=init)(g)
	g = InstanceNormalization(axis=-1)(g)
	g = Activation('relu')(g)
	
	g = Conv2D(3, (7,7), padding='same', kernel_initializer=init)(g)
	g = InstanceNormalization(axis=-1)(g)
	out_image = Activation('tanh')(g)
	
	model = Model(in_image, out_image)
	return model

def define_composite_model(g_model_1, d_model, g_model_2, image_shape):

	g_model_1.trainable = True
	d_model.trainable = False
	g_model_2.trainable = False

	input_gen = Input(shape=image_shape)
	gen1_out = g_model_1(input_gen)
	output_d = d_model(gen1_out)
	
	input_id = Input(shape=image_shape)
	output_id = g_model_1(input_id)
	
	output_f = g_model_2(gen1_out)
	
	gen2_out = g_model_2(input_id)
	output_b = g_model_1(gen2_out)
	
	model = Model([input_gen, input_id], [output_d, output_id, output_f, output_b])
	
	opt = Adam(lr=0.0002, beta_1=0.5)
	
	model.compile(loss=['mse', 'mae', 'mae', 'mae'], loss_weights=[1, 5, 10, 10], optimizer=opt)
	return model

def load_real_samples(filename):
  data = np.load(filename)
  X1, X2 = data['arr_0'], data['arr_1'][:2000]
  X1 = (X1 - 127.5) / 127.5
  X2 = (X2 - 127.5) / 127.5

  return [X1, X2]

def generate_real_samples(dataset, n_samples, patch_shape):
  ix = np.random.randint(0, dataset.shape[0], n_samples)
  X = dataset[ix]
  y = np.ones((n_samples, patch_shape, patch_shape, 1))
  return X, y

def generate_fake_samples(g_model, dataset, patch_shape):
  X = g_model.predict(dataset)
  y = np.zeros((len(X), patch_shape, patch_shape, 1))
  return X,y

def save_models(step, g_model_A2B, g_modelB2A):
  filename1 = '/content/drive/My Drive/Colab Notebooks/g_model_AtoB_%06d.h5' % (step+1)
  g_model_AtoB.save(filename1)
  filename2 = '/content/drive/My Drive/Colab Notebooks/g_model_BtoA_%06d.h5' % (step+1)
  g_model_BtoA.save(filename2)
  print('>Saved: %s and %s' % (filename1, filename2))

def summarize_performance(step, g_model, trainX, name, n_samples=5):
  X_in, _ = generate_real_samples(trainX, n_samples, 0)
  X_out, _ = generate_fake_samples(g_model, X_in, 0)
  X_in = (X_in - 1) / 2.0
  X_out = (X_out - 1) / 2.0

  for i in range(n_samples):
    plt.subplot(2, n_samples, i+1)
    plt.axis('off')
    plt.imshow(X_in[i])

  for i in range(n_samples):
    plt.subplot(2, n_samples, i+1)
    plt.axis('off')
    plt.imshow(X_out[i])

  filename1 = '%s_generated_plot_%06d.png' % (name, (step+1))
  plt.savefig(filename1)
  plt.close()

from random import random

def update_image_pool(pool, images, max_size=50):
  selected = list()
  for image in images:
    if len(pool) < max_size:
      pool.append(image)
      selected.append(image)
    elif random() < 0.5:
      selected.append(image)
    else:
      ix = np.random.randint(0, len(pool))
      selected.append(pool[ix])
      pool[ix] = image

  return np.asarray(selected)

def train(d_model_A, d_model_B, g_model_A2B, g_model_B2A, c_model_A2B, c_model_B2A, dataset):
  n_epochs, n_batch = 100, 4
  n_patch = d_model_A.output_shape[1]

  trainA, trainB = dataset
  
  poolA, poolB = list(), list()
  bat_per_epo = int(len(trainA) / n_batch)
  n_steps = bat_per_epo * n_epochs

  for i in range(n_steps):
    X_realA, y_realA = generate_real_samples(trainA, n_batch, n_patch)
    X_realB, y_realB = generate_real_samples(trainB, n_batch, n_patch)

    X_fakeA, y_fakeA = generate_fake_samples(g_model_B2A, X_realB, n_patch)
    X_fakeB, y_fakeB = generate_fake_samples(g_model_A2B, X_realA, n_patch)

    X_fakeA = update_image_pool(poolA, X_fakeA)
    X_fakeB = update_image_pool(poolB, X_fakeB)

##    cust = {'InstanceNormalization': InstanceNormalization}
##    opt = Adam(lr=0.0002, beta_1=0.5)
##
##    c_model_A2B = load_model('/content/drive/My Drive/Colab Notebooks/g_model_AtoB_000200.h5', cust)
##    c_model_A2B.compile(loss=['mse', 'mae', 'mae', 'mae'], loss_weights=[1, 5, 10, 10], optimizer=opt)
##
##    c_model_B2A = load_model('/content/drive/My Drive/Colab Notebooks/g_model_BtoA_000200.h5', cust)
##    c_model_B2A.compile(loss=['mse', 'mae', 'mae', 'mae'], loss_weights=[1, 5, 10, 10], optimizer=opt)
                        
    g_loss2, _, _, _, _ = c_model_B2A.train_on_batch([X_realB, X_realA], [y_realA, X_realA, X_realB, X_realA])

    dA_loss1 = d_model_A.train_on_batch(X_realA, y_realA)
    dA_loss2 = d_model_A.train_on_batch(X_fakeA, y_fakeA)

    #c_model_AtoB.load_weights('/content/drive/My Drive/weights.h5')    
    g_loss1, _, _, _, _ = c_model_AtoB.train_on_batch([X_realA, X_realB], [y_realB, X_realB, X_realA, X_realB])

    dB_loss1 = d_model_B.train_on_batch(X_realB, y_realB)
    dB_loss2 = d_model_B.train_on_batch(X_fakeB, y_fakeB)

    print('>%d, dA[%.3f,%.3f] dB[%.3f,%.3f] g[%.3f,%.3f]' % (i+1, dA_loss1,dA_loss2, dB_loss1,dB_loss2, g_loss1,g_loss2))

    if (i+1) % (bat_per_epo * 1) == 0:
      summarize_performance(i, g_model_A2B, trainA, 'A2B')
      summarize_performance(i, g_model_B2A, trainB, 'B2A')

    if (i+1) % (bat_per_epo) == 0:
      save_models(i, g_model_A2B, g_model_B2A)

dataset = load_real_samples('vangogh2photo.npz')
print('Loaded', dataset[0].shape, dataset[1].shape)

image_shape = dataset[0].shape[1:]

g_model_AtoB = define_generator(image_shape)
g_model_BtoA = define_generator(image_shape)

d_model_A = define_discriminator(image_shape)
d_model_B = define_discriminator(image_shape)

c_model_AtoB = define_composite_model(g_model_AtoB, d_model_B, g_model_BtoA, image_shape)
c_model_BtoA = define_composite_model(g_model_BtoA, d_model_A, g_model_AtoB, image_shape)

train(d_model_A, d_model_B, g_model_AtoB, g_model_BtoA, c_model_AtoB, c_model_BtoA, dataset)

